{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os librosa\n",
    "\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input, TimeDistributed, Bidirectional, Activation\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(str):\n",
    "    path = './Drum'\n",
    "    kits = os.listdir(path)\n",
    "    #kits.remove('.DS_Store')\n",
    "    \n",
    "    oh = []\n",
    "\n",
    "    for kit in kits:\n",
    "        if str == kit:\n",
    "            oh.append(1)\n",
    "        else:\n",
    "            oh.append(0)\n",
    "    \n",
    "    return np.array(oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make4096(wav):\n",
    "    while len(wav) < 4096:\n",
    "        wav = np.append(wav, np.array([0]))\n",
    "    return wav[:4096]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = 'Drum\\Snare\\9th Snare 38.wav'\n",
    "\n",
    "y_label = None\n",
    "x_label = None\n",
    "\n",
    "drumkit_path = './Drum'\n",
    "kits = os.listdir(drumkit_path)\n",
    "n=0\n",
    "\n",
    "for kit in kits:\n",
    "    path = os.path.join(drumkit_path, kit)\n",
    "    sounds = os.listdir(path)\n",
    "    \n",
    "    for sound in sounds:\n",
    "        wavfile = os.path.join(path, sound)\n",
    "        y, sr = librosa.load(wavfile)\n",
    "        yt, index = librosa.effects.trim(y=y, top_db=30)\n",
    "        y_16k = librosa.resample(yt, orig_sr=sr, target_sr=16000)\n",
    "        #yt16k = librosa.util.normalize(y_16k)\n",
    "        n += len(y_16k)\n",
    "        yt16k = make4096(y_16k)\n",
    "        yt16k = np.expand_dims(yt16k, axis=0)\n",
    "        \n",
    "        typ = onehot(kit)\n",
    "        typ = np.expand_dims(typ, axis=0)\n",
    "        \n",
    "        if x_label is None:\n",
    "            x_label = yt16k.copy()\n",
    "            y_label = typ.copy()\n",
    "        else:\n",
    "            x_label = np.concatenate((x_label, yt16k), axis=0)\n",
    "            y_label = np.concatenate((y_label, typ), axis=0)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n / 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_label, y_label, test_size=0.2, random_state=1234, stratify=y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy_test = np.argmax(y_test, axis = 1)\n",
    "yy_train = np.argmax(y_train, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 128\n",
    "dropout = 0.2\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "forward_layer = tf.keras.layers.LSTM(units=units, dropout=dropout, recurrent_dropout=dropout)\n",
    "backward_layer = tf.keras.layers.LSTM(units=units, activation='relu', go_backwards=True, dropout=dropout, recurrent_dropout=dropout)\n",
    "model.add(Bidirectional(forward_layer, backward_layer=backward_layer, input_shape=(4096)))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, yy_train, epochs=20, validation_split=0.2, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['loss']\n",
    "val_acc = history.history['val_loss']\n",
    "\n",
    "loss = history.history['accuracy']\n",
    "val_loss = history.history['val_accuracy']\n",
    "\n",
    "epochs_range = range(20)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Loss')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Loss')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Acc')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Acc')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =model.predict(x_test)\n",
    "ypred = np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test,yy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "classes = ['Conga&Bongo', 'Crash&OpenHat', 'Hi-Hat', 'Kick', 'Shaker', 'Snare', 'Tom']\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(yy_test, ypred), columns=classes, index=classes)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4bc97acf85d0056edc218ba7e370f7bc17be5942d47203e150f37936a6ad2e05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
