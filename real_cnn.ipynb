{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_INPUT_SIZE = (128, 20)\n",
    "DEFAULT_SR = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_axis(array, N):\n",
    "    if(array.shape[1] > N):\n",
    "        resized = array[:,:N]\n",
    "    else:\n",
    "        resized = np.lib.pad(array, ((0,0),(0,N - array.shape[1])),\\\n",
    "            'constant', constant_values=(np.min(array)))\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cnn_input(raw_audio):\n",
    "    frame_length = min(2048, len(raw_audio))\n",
    "    mel_spec = librosa.core.power_to_db(librosa.feature.melspectrogram(\n",
    "        y=raw_audio, sr=DEFAULT_SR, n_fft=frame_length,\n",
    "        hop_length=frame_length//4, n_mels=CNN_INPUT_SIZE[0])\n",
    "    )\n",
    "    # Truncate number of frames stored\n",
    "    m = min(CNN_INPUT_SIZE[1], mel_spec.shape[1])\n",
    "    N =20\n",
    "    mell = resize_axis(mel_spec[:, 0:m], N)\n",
    "    return mell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def onehot(str):\n",
    "    path = './Drum'\n",
    "    kits = os.listdir(path)\n",
    "    #kits.remove('.DS_Store')\n",
    "    \n",
    "    oh = []\n",
    "\n",
    "    for kit in kits:\n",
    "        if str == kit:\n",
    "            oh.append(1)\n",
    "        else:\n",
    "            oh.append(0)\n",
    "    \n",
    "    return np.array(oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cid2r\\anaconda3\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#path = 'Drum\\Snare\\9th Snare 38.wav'\n",
    "\n",
    "y_label = None\n",
    "x_label = None\n",
    "\n",
    "drumkit_path = './Drum'\n",
    "kits = os.listdir(drumkit_path)\n",
    "\n",
    "for kit in kits:\n",
    "    path = os.path.join(drumkit_path, kit)\n",
    "    sounds = os.listdir(path)\n",
    "    \n",
    "    for sound in sounds:\n",
    "        wavfile = os.path.join(path, sound)\n",
    "        y, sr = librosa.load(wavfile)\n",
    "        yt, index = librosa.effects.trim(y=y, top_db=30)\n",
    "        yt = librosa.util.normalize(yt)\n",
    "        k = extract_cnn_input(yt)\n",
    "        k = np.expand_dims(k, axis=0)\n",
    "        \n",
    "        typ = onehot(kit)\n",
    "        typ = np.expand_dims(typ, axis=0)\n",
    "        \n",
    "        if x_label is None:\n",
    "            x_label = k.copy()\n",
    "            y_label = typ.copy()\n",
    "        else:\n",
    "            x_label = np.concatenate((x_label, k), axis=0)\n",
    "            y_label = np.concatenate((y_label, typ), axis=0)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle Data\n",
    "\n",
    "shuffle = np.arange(y_label.shape[0])\n",
    "np.random.shuffle(shuffle)\n",
    "\n",
    "x_label = x_label[shuffle]\n",
    "y_label = y_label[shuffle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_label, y_label, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 128, 20)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change y_label to fit sci-kit specification (one-hot to categorical #)\n",
    "\n",
    "yy_test = np.array([])\n",
    "for i in range(x_test.shape[0]):\n",
    "    imsi = np.array([])\n",
    "    count = 0\n",
    "    for j in range(7):\n",
    "        if int(y_test[i,j]) == 0:\n",
    "            count += 1\n",
    "        else:\n",
    "            yy_test = np.concatenate((yy_test, np.array([count])), axis=0)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy_train = np.array([])\n",
    "for i in range(x_train.shape[0]):\n",
    "    imsi = np.array([])\n",
    "    count = 0\n",
    "    for j in range(7):\n",
    "        if int(y_train[i,j]) == 0:\n",
    "            count += 1\n",
    "        else:\n",
    "            yy_train = np.concatenate((yy_train, np.array([count])), axis=0)\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 7)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 128, 20)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 20,1)))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "18/18 [==============================] - 1s 17ms/step - loss: 16.7045 - accuracy: 0.2554\n",
      "Epoch 2/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.1243 - accuracy: 0.5768\n",
      "Epoch 3/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5812 - accuracy: 0.7964\n",
      "Epoch 4/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4835 - accuracy: 0.8161\n",
      "Epoch 5/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3783 - accuracy: 0.8625\n",
      "Epoch 6/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2892 - accuracy: 0.8911\n",
      "Epoch 7/20\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.2303 - accuracy: 0.9179\n",
      "Epoch 8/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2007 - accuracy: 0.9286\n",
      "Epoch 9/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1971 - accuracy: 0.9268\n",
      "Epoch 10/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1538 - accuracy: 0.9375\n",
      "Epoch 11/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1547 - accuracy: 0.9429\n",
      "Epoch 12/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1209 - accuracy: 0.9571\n",
      "Epoch 13/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0881 - accuracy: 0.9625\n",
      "Epoch 14/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0655 - accuracy: 0.9786\n",
      "Epoch 15/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0588 - accuracy: 0.9768\n",
      "Epoch 16/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0481 - accuracy: 0.9875\n",
      "Epoch 17/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0382 - accuracy: 0.9857\n",
      "Epoch 18/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0263 - accuracy: 0.9964\n",
      "Epoch 19/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0198 - accuracy: 0.9982\n",
      "Epoch 20/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0149 - accuracy: 0.9982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16bdf9d7df0>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, yy_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5843 - accuracy: 0.8643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5843215584754944, 0.8642857074737549]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, yy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model, \n",
    "                                         tf.keras.layers.Softmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = probability_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Shapes of all inputs must match: values[0].shape = [140] != values[1].shape = [140,7] [Op:Pack] name: stack",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_36180/3303177071.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m tf.math.confusion_matrix(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myy_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mpredictions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m )\n",
      "\u001b[1;32mc:\\Users\\cid2r\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cid2r\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7184\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7185\u001b[0m   \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7186\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Shapes of all inputs must match: values[0].shape = [140] != values[1].shape = [140,7] [Op:Pack] name: stack"
     ]
    }
   ],
   "source": [
    "tf.math.confusion_matrix(\n",
    "    labels=yy_test,\n",
    "    predictions=predict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9cda7dce2d78f3c21f6a73de63970ac35274352b7a0f13225446d99cae259cfd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
